# Results


1. **Model fit**
    * E.g., R2, Adj. R2, F test (for regressions)
    * E.g., Log likelihood test against a null model, hit rate, hit probabilities (for Logit models)

2. **Reporting your results**
    * Have a result table. Typically, this is not the output you get from SPSS or R, but a table you compile yourself.
        * E.g., a table combining <ins>multiple models</ins>    
        * E.g., a table dropping those 100 controls you added but that are not worth discussing
        * E.g., adding fit metrics to the table
    * It’s important to consider the exact situation you are in, and making the table fit your purpose

3. **Explaining your results**
    * Hypothesis tests (do this for each hypothesis) / and or revealing results about your expectation
        * Briefly repeat hypothesis (“In H1, we hypothesized that […]”)
        * Report the result in brackets (e.g., “Indeed, the effect of A on B is statistically significant (beta = xx, *p* = .012)")
        * Explain the result (the “why?”)
            * For a confirmed hypothesis, increase the intuition of your hypothesis (“apparently, as hypothesized, A leads to B **because** [repeat,
            etc.]…”)
            * For an unconfirmed hypothesis, explain why you don’t find the effect (e.g., a conceptual reason (effect doesn’t exist, and yo u h ave an
            **argument why it may not exist), or a measurement issue (e.g., data problems), etc.)**

    * Remaining variables
        * Explain the effects of control variables here (“The control variables age and gender have face valid effects. For example, all else equal, age increases the intention to purchase (beta = xx, *p* = .12). Education turns out to be not a significant predictor of intention to purchase (beta = xx, *p* = .63). This may be the case because

!!! note
      Note: While hypothesis tests are usually carried out against a *p* value of .05 (or sometimes .10), you need to report the exact *p* value in the text and tables with, e.g., three digits after the decimal point (e.g., *p* = .049, instead of *p* < .05). If you cannot give an exact *p* value because of rounding (e.g., the true *p* value is .00001, but it would round to *p* = .000), you need to write it down as *p* < .001. The *p* needs to be printed in italic always.



* **Consider showing model fit**

![Results1](/assets/results1.png){: style="width:600px"}

Datta[^1] 
[^1]:
Datta, H., Foubert, B., & Van Heerde, H. J. (2015). The challenge of retaining customers acquired with free trials. *Journal of Marketing Research,* 52(2), 217 234.


* **Consider plotting some results. E.g., coefficients of your estimated models, including error bars.**

![Results2](/assets/results2.png){: style="width:500px"}

Datta[^2] 
[^2]:
Datta, H., Knox, G., & Bronnenberg, B. J. (2017). Changing their tune: How consumers’ adoption of
online streaming affects music consumption and discovery. Marketing Science.

![Results3](/assets/results3.png){: style="height:400px;"}

Hannes[^3] 
[^3]:
Hannes Datta, Kusum L. Ailawadi, and Harald J. van Heerde (2017) How Well Does Consumer-Based
Brand Equity Align with Sales-Based Brand Equity and Marketing-Mix Response?. *Journal of
Marketing:* May 2017, Vol. 81, No. 3, pp. 1-20.


# “What-if” scenarios

* **Having estimated a regression model, you can come up with “what if” scenarios. Consider plotting the
  outcomes or showing them in tables.**
* **As an example, see the outcome of a simulation of what free trial versus regular acquisition does to a
  customer’s CLV.**

  ![Results Whatif](/assets/results4.png){: style="width:600px"}

Datta[^4] 
[^4]:
Datta, H., Foubert, B., & Van Heerde, H. J. (2015). The challenge of retaining customers acquired with free trials.* Journal of Marketing Research,* 52(2), 217-234.